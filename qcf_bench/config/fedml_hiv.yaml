common_args:
  training_type: "simulation"
  random_seed: 0

data_args:
  dataset: "ogbg-molhiv"
  data_cache_dir: ~/fedgraphnn_data/
  train_split: 0.9
  partition_method: "hetero"
  partition_alpha: 0.1

model_args:
  model: "graphormer" # ogb or graphormer
  num_tasks: 1

model_ogb_args:
  ogb_num_layer: 5
  ogb_emb_dim: 300
  ogb_gnn_type: "gcn"
  ogb_virtual_node: True
  ogb_residual: False
  ogb_drop_ratio: 0.5
  ogb_JK: "last"
  ogb_graph_pooling: "mean"

model_graphormer_args:
  graphormer_n_layers: 6
  graphormer_num_heads: 32
  graphormer_hidden_dim: 512
  graphormer_dropout_rate: 0.1
  graphormer_intput_dropout_rate: 0.0
  graphormer_weight_decay: 0.0
  graphormer_ffn_dim: 512
  graphormer_warmup_updates: 60000
  graphormer_tot_updates: 1000000
  graphormer_peak_lr: .0002
  graphormer_end_lr: .000000001
  graphormer_edge_type: "multihop"
  graphormer_multi_hop_max_dist: 5
  graphormer_attention_dropout_rate: 0.1

train_args:
  federated_optimizer: "FedAvg"
  client_id_list: "[]"
  client_num_in_total: 1
  client_num_per_round: 1
  comm_round: 100
  epochs: 1
  batch_size: 32
  client_optimizer: adam
  learning_rate: 0.00001
  weight_decay: 0.001
  metric: "aucroc"

validation_args:
  frequency_of_the_test: 1

device_args:
  worker_num: 1
  using_gpu: true
  gpu_mapping_file: config/gpu_mapping.yaml
  gpu_mapping_key: mapping_default

comm_args:
  backend: "MPI"
  is_mobile: 0

tracking_args:
  log_file_dir: ./log
  enable_wandb: false               # Toggle this whenever not being used (recommend false for bugtesting)
  wandb_key: my_wandb_key
  wandb_project: my_wand_project
  run_name: my_wandb_run            # Change this name for each different experiment
